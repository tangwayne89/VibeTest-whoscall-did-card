# BriefCard 開發計劃 (Development Plan)

## 專案概覽
基於 PRD 文件，BriefCard 是一個 LINE Bot，能將任何分享的連結轉換為豐富的視覺預覽卡片，提供一鍵保存、分享或稍後閱讀功能。

## 技術架構 (PoC 版本)
- **後端**: FastAPI + **Supabase** (PostgreSQL + Auth + Storage + Real-time)
- **前端**: React + Vite (LIFF)
- **爬蟲**: **Crawl4AI** + DeepSeek (成本優化)
- **AI 摘要**: OpenAI GPT-4o (後期可考慮 DeepSeek)
- **儲存**: Supabase Storage (S3 相容)
- **部署**: Vercel/Railway + Supabase
- **訊息**: LINE Messaging API + Flex Message

---

## Phase 0.5 - PoC (概念驗證階段)
**目標日期**: 2025年9月15日  
**主要目標**: URL檢測 + 靜態Flex卡片

### 📋 待辦清單

#### 1. Supabase 基礎設定
- [ ] 建立 Supabase 專案並獲取 API 金鑰
- [ ] 設計和建立資料庫結構 (bookmarks, shares, reminders)
- [ ] 設定 Row Level Security (RLS) 政策
- [ ] 測試 Supabase 連線和基本 CRUD 操作
- [ ] 建立 Git repository 和基本專案結構

#### 2. Crawl4AI 爬蟲系統
- [ ] 安裝和設定 Crawl4AI 環境
- [ ] 申請 DeepSeek API 金鑰 (成本優化)
- [ ] 實作基本網頁內容提取功能
- [ ] 測試不同類型網站的爬取效果
- [ ] 建立錯誤處理和重試機制

#### 3. FastAPI 後端開發
- [ ] 建立 FastAPI 專案架構
- [ ] 整合 Supabase 客戶端
- [ ] 實作書籤 API (創建、讀取、更新、刪除)
- [ ] 實作爬蟲服務整合
- [ ] 建立基本的錯誤處理和日誌系統

#### 4. LINE Bot 基礎功能
- [ ] 建立 LINE Developer Console 帳戶和 Bot Channel
- [ ] 實作 LINE webhook handler
- [ ] 實作 URL 檢測和自動爬取功能
- [ ] 建立基本的 Flex Message 卡片樣板
- [ ] 測試 Bot 基本互動功能

#### 5. 基本測試和驗證
- [ ] 單元測試框架設定
- [ ] 建立基本的 E2E 測試
- [ ] 部署到測試環境 (Vercel + Supabase)
- [ ] 效能測試和優化
- [ ] 驗證 URL 檢測和靜態卡片功能

---

## Phase 1.0 - Beta (核心功能開發)
**目標日期**: 2025年10月30日  
**主要目標**: 爬蟲 + AI摘要 + 保存/稍後閱讀 + LIFF書庫

### 📋 待辦清單

#### 1. 網頁爬蟲系統
- [ ] 安裝和設定 Playwright
- [ ] 實作基本網頁內容爬取功能
- [ ] 建立元數據提取器 (title, description, og:image)
- [ ] 實作圖片下載和快取機制
- [ ] 建立爬蟲錯誤處理和重試機制
- [ ] 加入 Goose3 進行內容清理和提取

#### 2. AI 摘要系統
- [ ] 整合 OpenAI GPT-4o API
- [ ] 建立摘要提示工程 (中英文支援)
- [ ] 實作摘要內容長度控制 (100-120 tokens)
- [ ] 建立摘要品質檢查機制
- [ ] 加入摘要失敗的備援方案

#### 3. 動態 Flex 卡片系統
- [ ] 重構卡片產生器支援動態內容
- [ ] 實作圖片比例處理 (1:1, 16:9)
- [ ] 建立卡片內容填充邏輯
- [ ] 加入快取機制提升效能
- [ ] 實作卡片預覽和偵錯工具

#### 4. 資料庫和儲存系統
- [ ] 設計和建立 PostgreSQL 資料庫架構
- [ ] 實作用戶和連結資料模型
- [ ] 建立 S3 儲存整合 (圖片快取)
- [ ] 實作資料庫遷移系統
- [ ] 建立備份和恢復策略

#### 5. 用戶操作功能
- [ ] 實作 "保存到書庫" 功能
- [ ] 建立資料夾管理系統
- [ ] 實作 "稍後閱讀" 預設資料夾
- [ ] 建立用戶權限和 ACL 系統
- [ ] 實作 5MB 儲存限制功能

#### 6. LIFF 前端開發
- [ ] 建立 React + Vite 專案架構
- [ ] 實作 LIFF SDK 整合
- [ ] 建立 "我的書庫" 介面 (網格/列表檢視)
- [ ] 實作資料夾 CRUD 功能
- [ ] 建立拖拉重新排序功能
- [ ] 實作分頁載入系統
- [ ] 建立個人資料設定頁面

#### 7. 效能和品質優化
- [ ] 實作 Redis 快取系統
- [ ] 建立 Task Queue 系統處理爬蟲工作
- [ ] 加入 API 速率限制
- [ ] 實作資料庫查詢優化
- [ ] 建立監控和日誌系統

---

## Phase 1.1 - GA (正式發布)
**目標日期**: 2025年12月15日  
**主要目標**: 分享功能 + 提醒排程器 + 分析系統

### 📋 待辦清單

#### 1. 分享功能系統
- [ ] 實作 Share Target Picker API 整合
- [ ] 建立分享訊息範本系統
- [ ] 實作原生 LINE 分享功能
- [ ] 加入分享權限控制
- [ ] 建立分享統計追蹤

#### 2. 智能提醒系統
- [ ] 建立 Google Cloud Scheduler 整合
- [ ] 實作用戶時區和時間偏好設定
- [ ] 建立每日推送 cron job
- [ ] 實作智能內容選擇演算法
- [ ] 建立 carousel 訊息產生器
- [ ] 加入推送頻率控制

#### 3. 進階 LIFF 功能
- [ ] 實作通知排程設定介面
- [ ] 建立時區選擇器
- [ ] 加入帳戶連結功能
- [ ] 實作儲存配額顯示
- [ ] 建立匯出/匯入功能
- [ ] 加入主題切換功能

#### 4. 分析和監控系統
- [ ] 實作事件追蹤系統 (card_generated, action_save, etc.)
- [ ] 建立用戶行為分析 dashboard
- [ ] 實作留存率分析
- [ ] 建立資料夾成長統計
- [ ] 加入平均連結數追蹤
- [ ] 實作效能監控和警報

#### 5. 企業級功能
- [ ] 實作 OAuth 2.0 / LINE Login
- [ ] 加入資料加密 (靜態和傳輸)
- [ ] 建立 PDPA & GDPR 合規系統
- [ ] 實作 99.5% 可用性監控
- [ ] 建立graceful degradation機制
- [ ] 加入自動擴展配置

#### 6. 最終優化和發布準備
- [ ] 進行全面安全審核
- [ ] 完成效能壓力測試 (10 QPS burst)
- [ ] 建立用戶文件和幫助系統
- [ ] 實作錯誤報告和回饋機制
- [ ] 完成多語言支援 (中英文)
- [ ] 準備正式發布流程

---

## 額外考慮事項

### 🔧 技術風險緩解
1. **爬蟲深度問題**: 建立分層爬取策略，先嘗試 readability 提取
2. **英雄圖片授權**: 研究免費圖片 API 整合 (Unsplash 等)
3. **Flex 訊息配額**: 建立使用量預估和限制機制
4. **重複連結處理**: 實作用戶級別去重邏輯
5. **多設備同步**: 建立 cloud-sync 機制

### 📊 品質保證
- 每個 Phase 結束前進行全面測試
- 建立 CI/CD pipeline 自動化部署
- 實作 A/B 測試框架用於功能驗證
- 建立用戶回饋收集和處理機制

### 🚀 部署策略
- 使用 Google Cloud Functions 實現無伺服器架構
- 建立 staging/production 環境分離
- 實作藍綠部署降低停機時間
- 建立災難恢復和備份策略

---

## 開發里程碑總結

| Phase | 核心功能 | 完成標準 | 預計日期 |
|-------|----------|----------|----------|
| **0.5 PoC** | URL檢測 + 靜態卡片 | Bot 能回應 URL 並發送基本卡片 | 2025/09/15 |
| **1.0 Beta** | 爬蟲 + AI + 書庫 | 完整的內容提取和儲存功能 | 2025/10/30 |
| **1.1 GA** | 分享 + 提醒 + 分析 | 完整產品功能和監控系統 | 2025/12/15 |

每個 milestone 都會有可測試的功能展示，確保專案按照預期進度推進。